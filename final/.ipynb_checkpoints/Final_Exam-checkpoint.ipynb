{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PROJECT: CS220 Spring 2020\n",
    "## This is an individual exam. Do not work with a partner! Only change \"submitter\" netid information. Good luck.\n",
    "- For majority of the questions you need to replace \"# Write your code here\" comment with your own code.\n",
    "- There are 27 questions, each of which will be weighted 0.55 points.\n",
    "- Unlike projects, you will receive partial credit for a question as long as your code runs and produces an output for each question.\n",
    "- Unlike projects, you do not have access to \"test.py\". Instead, you can use \"type_test.py\". This file does not check if your answers are correct, but it checks if your answers are in the correct format.\n",
    "- \"test.py\" will run \"lint.py\" and deduct points for linting errors. You will lose 0.1 points for each linting error. You will only lose points for warnings, not convention messages (just like in P10). type_test.py does not run the linter, so check with lint.py before turning your work in. For more information about the linter as well as how to run the full linter to see all of the automatically generated advice and feedback, please check out the linting README: https://github.com/msyamkumar/cs220-projects/tree/master/linter.\n",
    "- General hint: if you see a lot of hints / write up before a question, it is likely to be difficult question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project: final\n",
    "# submitter: xxie65\n",
    "# partner: none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended to use this cell to add import statements\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import csv, json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "#from pandas import DataFrame, Series\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>em { color: red; }</style> <style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just run this cell (it's just to make certain text red, but you don't need to understand it).\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>em { color: red; }</style> <style>.container { width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions q1 to q10 address topics covered by projects P2 to P4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Is *map_dummy* an *iterable* data structure? \n",
    "- Complete the below code to demonstrate this. \n",
    "- Your cell should only output either *True* or *False*. \n",
    "- You *should not hardcode* the answer to this question.\n",
    "- Hint: recall how to do nothing in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1: Is map_dummy an iterable data structure? True or False\n",
    "\n",
    "map_dummy = map(str, [4,2,1.0])\n",
    "try:\n",
    "    for item in map_dummy:\n",
    "        map_dummy = map_dummy\n",
    "    result = True\n",
    "except TypeError:\n",
    "    result = False\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Can we use a *list* as a *key in a dictionary*?\n",
    "- Complete the below code to demonstrate this. \n",
    "- Your cell should only output either *True* or *False*. \n",
    "- You *should not hardcode* the answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2: Can we use a list as a key in a dictionary? True or False\n",
    "\n",
    "try:\n",
    "    dic = {}\n",
    "    dic[[1, \"1\"]] = 1\n",
    "    result = True\n",
    "except TypeError:\n",
    "    result = False\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Complete *falsify* function such that if *bool_list* contains one or more occurences of \"False\", returned value is False. Otherwise returned value is True. \n",
    "- You may add multiple lines of code inside the Falsify function.\n",
    "- Your code must work with a list of any length!\n",
    "- Your cell should only output a list containing two boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3: Complete *Falsify* function such that if *bool_list* contains one or more occurences \n",
    "#of \"False\", returned value is False. Otherwise returned value is True. \n",
    "\n",
    "def falsify(bool_list):\n",
    "    if \"False\" in bool_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "# Test 1\n",
    "test_list = [\"True\", \"True\", \"False\", \"True\"]\n",
    "test_1 = falsify(test_list)\n",
    "\n",
    "# Test 2\n",
    "test_list = [\"True\", \"True\", \"Apple\", \"True\"]\n",
    "test_2 = falsify(test_list)\n",
    "[test_1, test_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following *data structure* to answer the next two questions *q4* and *q5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Student = namedtuple(\"Student\", [\"name\", \"id\"])\n",
    "data_struct = {\n",
    "    \"cs\": [Student(\"John\", \"netID123\"), Student(\"Martha\", \"netID123\")],\n",
    "    \"econ\": [Student(\"John\", \"netID5678_econ\"), Student(\"Peter\", \"netID5679_econ\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What is the *ID* for *John from Economics*?\n",
    "- Your cell should only output the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'netID5678_econ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4: What is the ID for John from Economics?\n",
    "\n",
    "data_struct[\"econ\"][0].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: List the *names* of all students in *CS*.\n",
    "- Your answer should be in the form of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Martha']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5: List the names of all students in CS.\n",
    "\n",
    "cs_stu = []\n",
    "for stu in data_struct[\"cs\"]:\n",
    "    cs_stu.append(stu.name)\n",
    "cs_stu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:  Use *list slicing* to right rotate list [1,2,3,4] by three places.\n",
    "- Hint: When you rotate a list like [1,2,3,4] right by one place, you get [4,1,2,3].\n",
    "- Your answer should be in the form of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6: Use list slicing to right rotate list [1,2,3,4] by three places\n",
    "\n",
    "original_list = [1,2,3,4]\n",
    "new_list = original_list[-3:] + original_list[:-3]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing cereal.csv dataset (q7 to q14)\n",
    "### Write a function that *reads* in the *cereal.csv* file and stores the data as a variable. \n",
    "- Make sure to write a generic function that takes csv file as input and returns the data (for reusability)\n",
    "- Download \"cereal.csv\" to the same local directory.\n",
    "- *Do not use any additional path* to your data file - this will *mess up grading*!\n",
    "- We will be using this variable through the next set of questions (q7 to q15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read csv file\n",
    "\n",
    "def process_csv(filename):\n",
    "    exampleFile = open(filename, encoding=\"utf-8\")\n",
    "    exampleReader = csv.reader(exampleFile)\n",
    "    exampleData = list(exampleReader)\n",
    "    exampleFile.close()\n",
    "    return exampleData\n",
    "\n",
    "cr_entire = process_csv(\"cereal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: What is the *carbohydrate content* in the cereal named \"*Cheerios*\"? \n",
    "- Recall that you shouldn't hardcode the index for looking up a particular column's value.\n",
    "- Follow the index lookup for all further questions.\n",
    "- You should make sure to look up the index of the column using the csv header first.\n",
    "- Your cell should output a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7: What is the carbohydrate content in the cereal named \"Cheerios\"?\n",
    "\n",
    "cr_header = process_csv(\"cereal.csv\")[0]\n",
    "cr_data = process_csv(\"cereal.csv\")[1:]\n",
    "\n",
    "for row in cr_entire:\n",
    "    if row[cr_header.index(\"name\")] == \"Cheerios\":\n",
    "        cheerios_carbo = float(row[cr_header.index(\"carbo\")])\n",
    "cheerios_carbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: What is the *cereal* with the *highest rating*?\n",
    "- Report your answer as a dictionary.\n",
    "- *key* as the *cereal name* and *value* as the *numerical rating*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All-Bran with Extra Fiber': 93.704912}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q8: What is the cereal with the highest rating?\n",
    "\n",
    "highest_rat = {}\n",
    "highest_r = 0\n",
    "for row in cr_data:\n",
    "    rating = float(row[cr_header.index(\"rating\")])\n",
    "    name = row[cr_header.index(\"name\")]\n",
    "    if rating > highest_r:\n",
    "        highest_r = rating\n",
    "        highest_cr = name\n",
    "highest_rat[highest_cr] = highest_r\n",
    "highest_rat     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Write *a function* that computes the *mininum, maximum, and average* for a given numerical column of the cereal data and returns these data as a dictionary. Report the basic statistics for the *fat* column.\n",
    "- Example output: \n",
    "```result = {\"min\": 0.1, \"max\":5.2, \"mean\": 2.2}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.0, 'max': 5.0, 'mean': 1.0129870129870129}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q9: Write a function that computes the mininum, maximum, and average for a given \n",
    "# numerical column of the cereal data and returns these data as a dictionary.\n",
    "# Report the basic statistics for the fat column.\n",
    "\n",
    "def find_stats(col_name):\n",
    "    result = {}\n",
    "    idx = cr_header.index(col_name)\n",
    "    mini = None\n",
    "    maxi = None\n",
    "    avg = None\n",
    "    total = 0\n",
    "    for row in cr_data:\n",
    "        value = float(row[idx])\n",
    "        if mini == None or value < mini:\n",
    "            mini = value\n",
    "        total += value\n",
    "        if maxi == None or value > maxi:\n",
    "            maxi = value\n",
    "    avg = total/len(cr_data)\n",
    "    result[\"min\"] = mini\n",
    "    result[\"max\"] = maxi\n",
    "    result[\"mean\"] = avg\n",
    "    return result\n",
    "        \n",
    "result = find_stats('fat')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Find the *difference* between the *average sugar content* of all cereals that are rated below 30 and the ones above 50.\n",
    "- Your cell should output a float value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.783882783882785"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q10: Find the difference between the average sugar content of all cereals \n",
    "# that are rated below 30 \n",
    "# and the ones above 50\n",
    "\n",
    "avg_sugar_below_30 = 0 \n",
    "avg_sugar_above_50 = 0\n",
    "\n",
    "below_30_n = 0\n",
    "above_50_n = 0\n",
    "for row in cr_data:\n",
    "    rating = float(row[cr_header.index(\"rating\")])\n",
    "    sugar = float(row[cr_header.index(\"sugars\")])\n",
    "    if rating < 30:\n",
    "        avg_sugar_below_30 += sugar\n",
    "        below_30_n += 1\n",
    "    if rating > 50:\n",
    "        avg_sugar_above_50 += sugar\n",
    "        above_50_n += 1\n",
    "\n",
    "avg_sugar_below_30 = avg_sugar_below_30 / below_30_n\n",
    "avg_sugar_above_50 = avg_sugar_above_50 / above_50_n\n",
    "\n",
    "avg_sugar_below_30 - avg_sugar_above_50 # don't change this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions q11 to q14 address topics covered by projects P5 and P6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: How many products are in the cereal dataset?\n",
    "- Your cell should output an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q11: How many products are in the cereal dataset?\n",
    "\n",
    "len(cr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: What is the *product name* in the cereal data that has the *third highest rating*?\n",
    "- Hints:\n",
    "   - You need need to re-order your cereal data by ratings.\n",
    "   - Recall that the typical function you use for re-ordering has a parameter called *key*, which enables you to write a getter function for lookup of specific column value.\n",
    "- Your cell should output str value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shredded Wheat spoon size'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q12: What is the product name in the cereal data that has the third highest rating?\n",
    "\n",
    "def sort_by_rating(row):\n",
    "    return float(row[cr_header.index(\"rating\")])\n",
    "\n",
    "sorted(cr_data, key = sort_by_rating, reverse = True)[2][cr_header.index(\"name\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13: What are *product names* that meet the following criteria:\n",
    "1. *2 ≤ fat ≤ 5*\n",
    "2. *rating ≥ 30*\n",
    "3. *100 ≤ sodium ≤ 200*\n",
    "- Your answer should be a list with the items names (str) sorted in lexicographical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Almond Delight',\n",
       " 'Clusters',\n",
       " \"Cracklin' Oat Bran\",\n",
       " 'Fruit & Fibre Dates; Walnuts; and Oats',\n",
       " 'Life',\n",
       " 'Muesli Raisins; Peaches; & Pecans',\n",
       " 'Mueslix Crispy Blend',\n",
       " 'Oatmeal Raisin Crisp',\n",
       " 'Raisin Nut Bran']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q13: What are product names that meet the following criteria:\n",
    "   # 2 ≤ fat ≤ 5\n",
    "   # rating ≥ 30\n",
    "   # 100 ≤ sodium ≤ 200\n",
    "\n",
    "names_q13 = []\n",
    "for row in cr_data:\n",
    "    name = row[cr_header.index(\"name\")]\n",
    "    fat = float(row[cr_header.index(\"fat\")])\n",
    "    rating = float(row[cr_header.index(\"rating\")])\n",
    "    sodium = float(row[cr_header.index(\"sodium\")])\n",
    "    if 2 <= fat <= 5:\n",
    "        if rating >= 30:\n",
    "            if 100 <= sodium <= 200:\n",
    "                names_q13.append(name)\n",
    "sorted(names_q13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14: Write a function *find_word(keyword)* that returns a list of product names that have *keyword* in the product name.\n",
    "- Keyword match:\n",
    "  - should be *case insensitive*\n",
    "  - should be *complete match (not a substring match)*, with the exception of \"'\" and \"-\" (see below example for details)\n",
    "  - apply split(...) method for handling / eliminating \"-\" and \"'\" from the comparsion\n",
    "  - Hint: this question is all about extracting individual words from the product name and iterating over those words. It is likely that you will need nested loops.\n",
    "- *Order the list* with the highest rated cereal first and the lowest rated cereal last:\n",
    "  - Hint: you already did something similar for #q12. Reuse the same getter function here.\n",
    "- The match result should not consider substring match:\n",
    "  - Let's say keyword is \"Apple\", and product names are [\"Apple pie\", \"Apple's seed\", \"Applewatch\", \"apple-pay\", \"apples\"].\n",
    "  - In this example only \"Apple pie\", \"Apple's seed\", and \"apple-pay\" matches with keyword. \n",
    "  - \"Applewatch\" and \"apples\" are NOT qualified since there are additional letters concatenated to the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Shredded Wheat'n'Bran\",\n",
       " 'Shredded Wheat spoon size',\n",
       " 'Shredded Wheat',\n",
       " 'Cream of Wheat (Quick)',\n",
       " 'Puffed Wheat',\n",
       " 'Nutri-grain Wheat',\n",
       " 'Frosted Mini-Wheat',\n",
       " 'Wheat Chex',\n",
       " 'Crispy Wheat & Raisins']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q14: Write a function find_word(keyword) that returns a list of product names that have \n",
    "# keyword in the product name.\n",
    "\n",
    "def find_word(keyword):\n",
    "    names = []\n",
    "    rows = []\n",
    "    for row in cr_data:\n",
    "        fullname = row[cr_header.index(\"name\")]\n",
    "        name_lst1 = fullname.split(\"-\")\n",
    "        name_lst2 = []\n",
    "        for item in name_lst1: \n",
    "            name_lst2 += item.split(\"'\")\n",
    "        name_lst3 = []\n",
    "        for sub in name_lst2:\n",
    "            name_lst3 += sub.split(\" \")\n",
    "        for pt in name_lst3:\n",
    "            if keyword == pt:\n",
    "                rows.append(row)\n",
    "        new_rows = sorted(rows, key = sort_by_rating, reverse = True)\n",
    "    for cr in new_rows:\n",
    "        names.append(cr[0])\n",
    "    return names\n",
    "\n",
    "# After creating the function, what is the result of find_word(\"Wheat\")?\n",
    "find_word(\"Wheat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing player_data.csv dataset (q15 to q18)\n",
    "## Questions q15 to q18 address topics covered by project P7.\n",
    "\n",
    "### Read *player_data.csv* using the csv reading function that you already wrote.\n",
    "- Download the NBA players dataset \"player_data.csv\" to the same local directory.\n",
    "- *Do not use any additional path* to your data file - this will *mess up grading*!\n",
    "- We will be using this variable through the next set of questions (q15 to q18).\n",
    "- For all the questions you should *skip all players who have some entries in the column are missing* (i.e., some entry is just the empty string).\n",
    "- Consider writing a *cell* function to convert appropriate columns into their correct data type!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_entire = process_csv(\"player_data.csv\")\n",
    "pl_header = process_csv(\"player_data.csv\")[0]\n",
    "pl_data = process_csv(\"player_data.csv\")[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15 : How many *complete players* in the dataset? \n",
    "- Reminder: skip all players who have some entries in the column are missing.\n",
    "- Hint: answer should be lower than 4550!\n",
    "- Your cell should output an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4213"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q15: How many complete players in the dataset? skip all players who have some entries \n",
    "# in the column are missing. i.e. one or more of the entries is the empty string.\n",
    "\n",
    "complete_pl_data = []\n",
    "for row in pl_data:\n",
    "    if not \"\" in row:\n",
    "        complete_pl_data += [row]\n",
    "len(complete_pl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16: What are the *stats* for the player whose name is \"*Michael Jordan*\"?\n",
    "- Answer in the form of a dict. \n",
    "- See the example below:\n",
    "```example = {'name': 'Alaa Abdelnaby',\n",
    " 'year_start': 1991,\n",
    " 'year_end': 1995,\n",
    " 'position': 'F-C',\n",
    " 'height': '6-10',\n",
    " 'weight': 240,\n",
    " 'birth_date': 'June 24, 1968',\n",
    " 'college': 'Duke University'}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Michael Jordan',\n",
       " 'year_start': 1985,\n",
       " 'year_end': 2003,\n",
       " 'position': 'G-F',\n",
       " 'height': '6-6',\n",
       " 'weight': 195,\n",
       " 'birth_date': 'February 17, 1963',\n",
       " 'college': 'University of North Carolina'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q16: What are the stats for the player whose name is \"Michael Jordan\"?\n",
    "\n",
    "def stats(colname, cellname):\n",
    "    mj_stats = {}\n",
    "    for row in complete_pl_data:\n",
    "        if row[pl_header.index(colname)] == cellname:\n",
    "            for colname in pl_header:\n",
    "                mj_stats[colname] = row[pl_header.index(colname)]\n",
    "                if colname in (\"year_start\", \"year_end\", \"weight\"):\n",
    "                    mj_stats[colname] = int(row[pl_header.index(colname)])\n",
    "    return mj_stats\n",
    "\n",
    "stats(\"name\", \"Michael Jordan\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17: What are the *stats* for the *players* whose college is *\"University of Wisconsin\"*?\n",
    "- Your output should be a list of dictionaries. \n",
    "- Each dictionary should be similar to the example in the previous question.\n",
    "- Hint: consider writing a bucketize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'},\n",
       " {'name': 'Alando Tucker',\n",
       "  'year_start': 2008,\n",
       "  'year_end': 2010,\n",
       "  'position': 'F',\n",
       "  'height': '6-6',\n",
       "  'weight': 205,\n",
       "  'birth_date': 'February 11, 1984',\n",
       "  'college': 'University of Wisconsin'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q17: What are the stats for the players whose college is \"University of Wisconsin\"\n",
    "\n",
    "def bucketize(keyword, cellname): \n",
    "    pl_dict = {}\n",
    "    for row in complete_pl_data:\n",
    "        attr = row[pl_header.index(keyword)]\n",
    "        if attr == cellname: \n",
    "            if not attr in pl_dict:\n",
    "                pl_dict[attr] = []\n",
    "            pl_dict[attr].append(stats(keyword, cellname))\n",
    "    return pl_dict\n",
    "\n",
    "bucketize(\"college\", \"University of Wisconsin\")['University of Wisconsin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18: What is the average *weight* for each *position*?\n",
    "- Answer with a dictionary, mapping the key \"position\" to the value \"average weight\" (float type).\n",
    "- Average is the same as mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F-C': 222.91944444444445,\n",
       " 'C-F': 228.25615763546799,\n",
       " 'C': 242.2192118226601,\n",
       " 'G': 186.82811459027315,\n",
       " 'F': 217.98585690515807,\n",
       " 'F-G': 202.60487804878048,\n",
       " 'G-F': 197.01785714285714}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q18: What is the average \"weight\" for each \"position\"?\n",
    "\n",
    "def bucketize2(keyword): \n",
    "    wt_dict = {}\n",
    "    for row in complete_pl_data:\n",
    "        attr = row[pl_header.index(keyword)]\n",
    "        if not attr in wt_dict:\n",
    "            wt_dict[attr] = []\n",
    "        wt_dict[attr].append(row)\n",
    "    return wt_dict\n",
    "\n",
    "avg_wt = {}\n",
    "for pos in bucketize2(\"position\"):\n",
    "    tot_wt = 0\n",
    "    for player in bucketize2(\"position\")[pos]:\n",
    "        tot_wt += int(player[pl_header.index(\"weight\")])\n",
    "    avg_wt[pos] = tot_wt/len(bucketize2(\"position\")[pos])\n",
    "    \n",
    "avg_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing netflix_titles.html (to be converted to Python data structure) dataset (q19 to q21)\n",
    "## Question q19 addresses topics covered by project P10.\n",
    "\n",
    "### Question 19: Download and parse netflix_titles.html and write the data into a list-of-lists or list-of-dictionaries\n",
    "- This dataset *should not be manually* downloaded!\n",
    "- To download this html file, complete the below download function (this part is from project P10).\n",
    "- Next step is to parse the html data to store it in a data structure, either list-of-lists or list-of-dictionaries.\n",
    "- You need to use BeautifulSoup functions find() and find_all().\n",
    "- Recall that *table* tag contains *tr* tags for rows.\n",
    "- Recall that *tr* tags contain *td* tags for the actual data.\n",
    "- Recall that you can extract *text* from any tag.\n",
    "- The headers for this dataset are the following:\n",
    "```\n",
    "['show_id',\n",
    " 'type',\n",
    " 'title',\n",
    " 'director',\n",
    " 'cast',\n",
    " 'country',\n",
    " 'date_added',\n",
    " 'release_year',\n",
    " 'rating',\n",
    " 'duration',\n",
    " 'listed_in',\n",
    " 'description']\n",
    "```\n",
    "- This cell should output the following after successful parsing:\n",
    "```\n",
    "['Norm of the North: King Sized Adventure',\n",
    " 'Jandino: Whatever it Takes',\n",
    " 'Transformers Prime']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Norm of the North: King Sized Adventure',\n",
       " 'Jandino: Whatever it Takes',\n",
       " 'Transformers Prime']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q19: Download and parse netflix_titles.html.\n",
    "#Follow the detailed steps given in the below function outline.\n",
    "\n",
    "# Complete the missing parts in the below download function\n",
    "\n",
    "def download(filename, url):\n",
    "    # We do not download again if the file already exists\n",
    "    if os.path.exists(filename):\n",
    "        return (str(filename) + \" already exists!\")\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(resp.text)\n",
    "    f.close()\n",
    "    # Download the file from URL and save it in `filename`\n",
    "\n",
    "    return (str(filename) + \" created!\")\n",
    "\n",
    "#Do not change this line\n",
    "download(\"netflix_titles.html\", \\\n",
    "         \"https://raw.githubusercontent.com/msyamkumar/cs220-projects/master/spring20/final/netflix_titles.html\")\n",
    "\n",
    "def parse_html_contents(html_file):\n",
    "    #To store the parsed data\n",
    "    netflix_data = []\n",
    "    \n",
    "    # Open and read the html file\n",
    "    f = open(html_file)\n",
    "    html_string = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    # Create a BeautifulSoup type\n",
    "    doc = BeautifulSoup(html_string, \"html.parser\")\n",
    "            \n",
    "    # Find the dataset table\n",
    "    table = doc.find(\"table\") #find all tables in the doc object\n",
    "    #assert len(table) == 1 #make sure only 1 table in the html file\n",
    "    \n",
    "    # Find the rows in the table. Hint: separate your header versus data processing here.\n",
    "    trs = table.find_all(\"tr\") #find all rows\n",
    "    headers = trs[0].find_all(\"td\")\n",
    "    datarows = trs[1:]\n",
    "    \n",
    "    # Find data for header row: you can generate a list of str here (see above output for reference)\n",
    "    netflix_header = []\n",
    "    for header in headers:\n",
    "        netflix_header.append(header.get_text())\n",
    "        \n",
    "    # Find data for the remaining rows:\n",
    "    # To store this dataset, choose between list-of-lists or list-of-dictionaries\n",
    "    for row in datarows:\n",
    "        rowlist = []\n",
    "        data = row.find_all(\"td\")\n",
    "        for tag in data:\n",
    "            rowlist.append(tag.get_text())\n",
    "        netflix_data.append(rowlist)\n",
    "        \n",
    "    return netflix_data \n",
    "\n",
    "    # If you want to return header data also, change the above line to something like this:\n",
    "    # return netflix_header, netflix_data\n",
    "    \n",
    "netflix_header = ['show_id',\n",
    "'type',\n",
    "'title',\n",
    "'director',\n",
    "'cast',\n",
    "'country',\n",
    "'date_added',\n",
    "'release_year',\n",
    "'rating',\n",
    "'duration',\n",
    "'listed_in',\n",
    "'description']\n",
    "    \n",
    "netflix_data = parse_html_contents(\"netflix_titles.html\") #Do not change these lines\n",
    "\n",
    "top_3_titles = []\n",
    "for row in netflix_data[:3]:\n",
    "    # Retrieve top 3 titles from your data structure (see above output for reference)\n",
    "    top_3_titles.append(row[netflix_header.index(\"title\")])\n",
    "top_3_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions q20 to q21 address topics covered by project P8.\n",
    "### Question 20: List the *first 10* TV shows' *titles* in the dataset.\n",
    "- There are different types of Netflix videos in this dataset, such as TV shows and movies. \n",
    "- This question asks you to list *only* first 10 *TV shows*.\n",
    "- Your cell should output a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transformers Prime',\n",
       " 'Transformers: Robots in Disguise',\n",
       " 'Apaches',\n",
       " 'Fire Chasers',\n",
       " 'Castle of Stars',\n",
       " 'First and Last',\n",
       " \"Archibald's Next Big Thing\",\n",
       " 'The Spy',\n",
       " 'No Tomorrow',\n",
       " 'Frequency']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q20: List the first 10 TV shows' titles in the dataset.\n",
    "\n",
    "ten_tv = []\n",
    "for vid in netflix_data:\n",
    "    if vid[netflix_header.index(\"type\")] == \"TV Show\":\n",
    "        ten_tv.append(vid[netflix_header.index(\"title\")])\n",
    "ten_tv[:10]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 21: How many *movies* released *after 2015 (inclusive)* are in this dataset?\n",
    "- This question asks you to consider *only movies*.\n",
    "- Your cell should output an int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q21: How many movies released after 2015 (inclusive) are in this dataset?\n",
    "\n",
    "ten_mov = []\n",
    "for vid in netflix_data:\n",
    "    if vid[netflix_header.index(\"type\")] == \"Movie\":\n",
    "        if int(vid[netflix_header.index(\"release_year\")]) >= 2015:\n",
    "            ten_mov.append(vid[netflix_header.index(\"title\")])\n",
    "len(ten_mov)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the movies data in the data folder (q22, q23).\n",
    "## Questions q22, q23 address topics covered by project P9.\n",
    "\n",
    "- The data folder consists of two things\n",
    "  1. movies.csv, which consists of the movie_id, title, and genres corresponding to the movie. \n",
    "  2. The users directory inside the data folder consists of the ratings given by 10 users in files named from 1.json to 10.json.\n",
    "     - The first attribute in the file refers to the movie_id, and second attribute refers to the rating given by that user to that movie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 22: What is the *average rating* for the movie with id *34*?\n",
    "- Combine all the json files in the users directory inside the data directory and calculate the average rating for the movie ids present in these files.\n",
    "- Remember a particular movie_id can be part of multiple files!\n",
    "- You can read the json files one by one and add the entries to a dictionary:\n",
    "  - with the key as the movie_id (in integer format) and as the value you can maintan a list of ratings \n",
    "  - each rating value stored as a float\n",
    "- You can now iterate over the created dictionary and calculate the average rating corresponding to each movie_id\n",
    "- Your cell should output a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q22: What is the average rating for the movie with id 34?\n",
    "\n",
    "filename_list = os.listdir(os.path.join(\"data\", \"users\"))\n",
    "\n",
    "# read json files\n",
    "def read_json(filename):\n",
    "    f = open(os.path.join(\"data\", os.path.join(\"users\", filename)), encoding=\"utf-8\")\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "rt_dict = {}\n",
    "for file in filename_list:\n",
    "    read_file = read_json(file)\n",
    "    for key in read_file:\n",
    "        rating = float(read_file[key])\n",
    "        if not int(key) in rt_dict:\n",
    "            rt_dict[int(key)] = []\n",
    "        rt_dict[int(key)].append(rating)\n",
    "\n",
    "avgrt_dict = {}\n",
    "for movid in rt_dict:\n",
    "    ratings = rt_dict[movid]\n",
    "    tot_rt = 0\n",
    "    for rating in ratings:\n",
    "        tot_rt += rating\n",
    "    avg_rt = tot_rt / len(ratings)\n",
    "    avgrt_dict[movid] = avg_rt\n",
    "\n",
    "avgrt_dict[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 23: What is the *minimum rating* for the movie *Batman (1989)*?\n",
    "- You can find the names of the movies in the CSV file.\n",
    "- Make sure to use *os.path.join* while opening the file and do not hardcode the slashes!\n",
    "- You have to combine the data from the CSV file with the data from the JSON files.\n",
    "- Your cell should output a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q23: What is the *minimum rating* for the movie *Batman (1989)*?\n",
    "\n",
    "def read_csv(filename):\n",
    "    path = os.path.join(\"data\", filename)\n",
    "    mov_file = open(path, encoding='utf-8')\n",
    "    file_reader = csv.reader(mov_file)\n",
    "    mov_data = list(file_reader)\n",
    "    mov_file.close()\n",
    "    return mov_data\n",
    "\n",
    "mv_header = read_csv(\"movies.csv\")[0]\n",
    "mv_data = read_csv(\"movies.csv\")[1:]\n",
    "for mov in mv_data:\n",
    "    if mov[mv_header.index(\"title\")] == \"Batman (1989)\":\n",
    "        btm_id = int(mov[mv_header.index(\"movieId\")])\n",
    "\n",
    "min_btm_rt = None\n",
    "for rt in rt_dict[btm_id]:\n",
    "    if min_btm_rt == None or rt < min_btm_rt:\n",
    "        min_btm_rt = rt\n",
    "min_btm_rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing countries.db - same dataset as P10 (q24 to q27).\n",
    "## Questions q24 to q27 address topics covered by project P10.\n",
    "- Create a sqlite connection to this database.\n",
    "- You can use either SQL querries or Pandas statements to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'countries.db'\n",
    "assert os.path.exists(path)    # make sure path exists\n",
    "conn = sqlite3.connect(path)    # start new connection\n",
    "pd.read_sql(\"select*from sqlite_master\", conn)    # select everything\n",
    "\n",
    "def qry(sql):    # create function to run sql query\n",
    "    return pd.read_sql(sql, conn)\n",
    "\n",
    "countries = qry(\"select * from countries\")\n",
    "capitals = qry(\"select * from capitals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 24: What is the *capital* of *Namibia*?\n",
    "- Answer as a python string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Windhoek'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q24: What is the capital of Namibia?\n",
    "\n",
    "cn = qry (\"\"\"\n",
    "SELECT capital\n",
    "FROM capitals\n",
    "WHERE country = \"Namibia\"\n",
    "\"\"\")\n",
    "cn.iloc[0].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 25: What is the *population* of *each continent*?\n",
    "- Answer as a Pandas Dataframe, sorted by population from highest to lowest. \n",
    "- The image in the cell below shows the first two lines of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>3739902863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa</td>\n",
       "      <td>824954038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>792053486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North America</td>\n",
       "      <td>515041558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South America</td>\n",
       "      <td>375441666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32163025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       continent  population\n",
       "0           Asia  3739902863\n",
       "1         Africa   824954038\n",
       "2         Europe   792053486\n",
       "3  North America   515041558\n",
       "4  South America   375441666\n",
       "5      Australia    32163025"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q25 What is the population of each continent?\n",
    "\n",
    "df_25 = qry (\"\"\"\n",
    "SELECT continent, sum(population) as population\n",
    "FROM countries\n",
    "group by continent\n",
    "order by population desc\n",
    "\"\"\")\n",
    "df_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img population_of_continent.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"population_of_continent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 26: *Plot the total population* of each continent.\n",
    "- Prepare a bar plot. \n",
    "- Put continents on the x-axis and total area on the y-axis. \n",
    "- The continents should be sorted along the x-axis alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'total population')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# q26 Plot the total population of each continent? \n",
    "\n",
    "matplotlib.rcParams[\"font.size\"] = 14\n",
    "\n",
    "df_26 = qry (\"\"\"\n",
    "SELECT continent, sum(population) as population\n",
    "FROM countries\n",
    "group by continent\n",
    "order by continent\n",
    "\"\"\")\n",
    "\n",
    "ax_26 = df_26.plot.bar(x = \"continent\", y = \"population\", color = \"black\", legend = False)\n",
    "ax_26.set_xlabel(\"continents\")\n",
    "ax_26.set_ylabel(\"total population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 27: What is the *population density (population / area)* of all the *top 7* most dense *countries in Europe*?\n",
    "- Report these as a Pandas DataFrame sorted in decreasing order of population density. \n",
    "- The image below shows the first 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monaco</td>\n",
       "      <td>16271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malta</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  population density\n",
       "0          Monaco               16271\n",
       "1           Malta                1266\n",
       "2      San Marino                 479\n",
       "3     Netherlands                 397\n",
       "4         Belgium                 339\n",
       "5  United Kingdom                 247\n",
       "6         Germany                 230"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q27 What is the population density (population / area) of all the top 7 most \n",
    "# dense countries in Europe. \n",
    "\n",
    "qry (\"\"\"\n",
    "SELECT country, population / area as `population density`\n",
    "FROM countries\n",
    "WHERE continent = \"Europe\"\n",
    "order by `population density` desc\n",
    "limit 7\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"population_density.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection to the database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, you are all done with work for CS220 course :) Mike and Meena wish you the best of luck for a bright future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
